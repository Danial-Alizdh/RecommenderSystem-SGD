{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data.txt and find set users and items\n",
    "\n",
    "data_ui = []\n",
    "with open(\"./data.txt\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        data_ui.append([int(line.split(\" \")[0]), [int(i) for i in line.split(\" \")[1:len(line.split(\" \"))-1]]])\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "set_item = set()\n",
    "for u, i in data_ui:\n",
    "    set_item.update(i)\n",
    "\n",
    "R = np.zeros((len(data_ui), len(set_item)+1))\n",
    "for user_id, item_ids in data_ui:\n",
    "    for item_id in item_ids:\n",
    "        R[user_id, item_id] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "R_train = R\n",
    "\n",
    "user_test_sample = random.sample(range(0, len(data_ui)), int(len(data_ui)*0.4))\n",
    "\n",
    "for i in user_test_sample:\n",
    "    user_id, items_ids = data_ui[i]\n",
    "\n",
    "    item_test_sample = random.sample(item_ids, int(len(item_ids)*0.2))\n",
    "\n",
    "    for item_id in item_ids:\n",
    "        R_train[i, item_id] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization:\n",
    "    def __init__(self, num_items, num_users, num_factors, learning_rate, regularization_rate, num_iterations):\n",
    "        \"\"\"\n",
    "        Initialize the Matrix Factorization model.\n",
    "\n",
    "        Args:\n",
    "            items (array): All items.\n",
    "            users (array): All users.\n",
    "            train_item (array): Train items.\n",
    "            num_factors (int): Number of latent factors.\n",
    "            learning_rate (float): Learning rate for gradient descent.\n",
    "            regularization_rate (float): Regularization rate for L2 regularization.\n",
    "            num_iterations (int): Number of iterations for training.\n",
    "        \"\"\"\n",
    "        self.num_items = num_items\n",
    "        self.num_users = num_users\n",
    "        self.num_factors = num_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization_rate = regularization_rate\n",
    "        self.num_iterations = num_iterations\n",
    "\n",
    "        # Initialize Q and P matrices with random values\n",
    "        # Start your code\n",
    "\n",
    "        # Initialize user and item feature matrices\n",
    "        self.user_features = np.random.normal(scale= 1/self.num_factors, size=(self.num_users, self.num_factors))\n",
    "        self.item_features = np.random.normal(scale= 1/self.num_factors, size=(self.num_items+1, self.num_factors))\n",
    "\n",
    "        # End your code\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Compute the sigmoid function.\n",
    "\n",
    "        Args:\n",
    "            x (float): Input value.\n",
    "\n",
    "        Returns:\n",
    "            float: Sigmoid value.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def update_parameters(self, R):\n",
    "        \"\"\"\n",
    "        Update the parameters Q and P using Stochastic Gradient Descent.\n",
    "\n",
    "        Args:\n",
    "            R (ndarray): Rating matrix.\n",
    "        \"\"\"\n",
    "        # Start your code\n",
    "        \n",
    "        temp = [\n",
    "            (u, i)\n",
    "            for u in range(self.num_users)\n",
    "            for i in range(self.num_items)\n",
    "            if R[u, i] > 0\n",
    "        ]\n",
    "        # Stochastic Gradient Descent (SGD) training loop\n",
    "        for epoch in range(self.num_iterations):\n",
    "            print(f\"Epoch {epoch+1} started\")\n",
    "            for u, i in temp:\n",
    "                predict = self.predict_rating(i, u)\n",
    "                self.user_features[u, :] += self.learning_rate * ((1- self.sigmoid(R[u, i] - predict)) + 2 * (self.regularization_rate * self.user_features[u, :]))\n",
    "                self.item_features[i, :] += self.learning_rate * ((1- self.sigmoid(R[u, i] - predict)) + 2 * (self.regularization_rate * self.item_features[i, :]))\n",
    "        \n",
    "        print(\"Train completed\")\n",
    "        # End your code\n",
    "\n",
    "    def train(self, R):\n",
    "        \"\"\"\n",
    "        Train the Matrix Factorization model.\n",
    "\n",
    "        Args:\n",
    "            R (ndarray): Rating matrix.\n",
    "        \"\"\"\n",
    "        self.update_parameters(R)\n",
    "\n",
    "    def predict_rating(self, i, u):\n",
    "        \"\"\"\n",
    "        Predict the rating for item i and user u.\n",
    "\n",
    "        Args:\n",
    "            i (int): Item index.\n",
    "            u (int): User index.\n",
    "\n",
    "        Returns:\n",
    "            float: Predicted rating.\n",
    "        \"\"\"\n",
    "        # Start your code\n",
    "\n",
    "        return np.dot(self.item_features[i, :], self.user_features[u, :].T)\n",
    "\n",
    "        # End your code\n",
    "\n",
    "    def evaluate(self, users_list, groundTruth_list, topk=10):\n",
    "        \"\"\"\n",
    "        Evaluate trained model for item i and user u\n",
    "\n",
    "        Args:\n",
    "            users_list (list): Users indexes list.\n",
    "            groundTruth_list (list) : list of items in users test set\n",
    "            topk (int): threshold for top item selection\n",
    "\n",
    "        Returns:\n",
    "            float: sum(Intersection between topk predicted items and user profile in test set / user profile size in test set) / len(users_list)\n",
    "        \"\"\"\n",
    "        # Start your code\n",
    "        acc = 0\n",
    "        for user_index in users_list:\n",
    "            items = groundTruth_list[user_index]\n",
    "            predict = np.dot(self.user_features[user_index, :], self.item_features.T)\n",
    "            index_sorted_predict = np.argsort(predict)[::-1]\n",
    "            topk_items = index_sorted_predict[:topk]\n",
    "            same = set(topk_items).intersection(items)\n",
    "            acc += (len(same) / len(items))        \n",
    "        return acc / len(users_list)\n",
    "    \n",
    "        # End your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = len(set_item)\n",
    "num_users = len(data_ui)\n",
    "num_factors = 500\n",
    "learning_rate = 0.1\n",
    "regularization_rate = 0.1\n",
    "num_iterations = 50\n",
    "\n",
    "R = None  # rating matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_list = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.02, 0.015, 0.000001, 1.000001, 0.0000001]\n",
    "\n",
    "for learning_rate in learning_rate_list:\n",
    "    model = MatrixFactorization(num_items, num_users, num_factors, learning_rate, regularization_rate, num_iterations)\n",
    "\n",
    "    model.train(R_train)\n",
    "\n",
    "    print(f\"Learning_rate = {learning_rate}\")\n",
    "    # Test prediction for item 0 and user 0\n",
    "    item_index = 0\n",
    "    user_index = 0\n",
    "    prediction = model.predict_rating(item_index, user_index)\n",
    "    print(f\"Predicted rating for item {item_index} and user {user_index}: {prediction}\")\n",
    "\n",
    "    # Evaluate model for users in test set\n",
    "    user_indexes = user_test_sample\n",
    "    groudTruths = {}\n",
    "\n",
    "    for i in user_test_sample :\n",
    "        (user_id, item_ids) = data_ui[i]\n",
    "        groudTruths[user_id] = item_ids\n",
    "\n",
    "    result = model.evaluate(user_indexes, groudTruths)\n",
    "    print(f\"Accuracy for model: {result}\")\n",
    "    print(\"********************************************\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
